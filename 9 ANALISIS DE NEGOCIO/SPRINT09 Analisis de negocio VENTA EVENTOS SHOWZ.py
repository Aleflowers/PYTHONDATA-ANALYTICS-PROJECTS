#!/usr/bin/env python
# coding: utf-8

# Hola **Alejandra**!
# 
# Soy **Patricio Requena** üëã. Es un placer ser el revisor de tu proyecto el d√≠a de hoy!
# 
# Revisar√© tu proyecto detenidamente con el objetivo de ayudarte a mejorar y perfeccionar tus habilidades. Durante mi revisi√≥n, identificar√© √°reas donde puedas hacer mejoras en tu c√≥digo, se√±alando espec√≠ficamente qu√© y c√≥mo podr√≠as ajustar para optimizar el rendimiento y la claridad de tu proyecto. Adem√°s, es importante para m√≠ destacar los aspectos que has manejado excepcionalmente bien. Reconocer tus fortalezas te ayudar√° a entender qu√© t√©cnicas y m√©todos est√°n funcionando a tu favor y c√≥mo puedes aplicarlos en futuras tareas. 
# 
# _**Recuerda que al final de este notebook encontrar√°s un comentario general de mi parte**_, empecemos!
# 
# Encontrar√°s mis comentarios dentro de cajas verdes, amarillas o rojas, ‚ö†Ô∏è **por favor, no muevas, modifiques o borres mis comentarios** ‚ö†Ô∏è:
# 
# 
# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si todo est√° perfecto.
# </div>
# 
# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.
# </div>
# 
# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.
# </div>
# 
# Puedes responderme de esta forma:
# <div class="alert alert-block alert-info">
# <b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>
# </div>

# # Analisis para optimizar los Gastos de Marketing de Showz

# Paso 1. Acceda los datos y prep√°ralos para el an√°lisis

# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Alejandra, la presentaci√≥n de los notebooks es importante en esta profesi√≥n, por lo que te pedir√≠a incluir un t√≠tulo y una introducci√≥n al mismo. Los t√≠tulos los puedes generar escribiendo de la siguiente manera `# T√≠tulo` en las celdas tipo markdown (no olvides el espacio despu√©s del #) y se ven de la siguiente forma:
#     
# # T√≠tulo
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (2da Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Correcto, as√≠ es mucho mejor la presentaci√≥n
# </div>

# In[22]:


import pandas as pd

visits = pd.read_csv('/datasets/visits_log_us.csv')
orders = pd.read_csv('/datasets/orders_log_us.csv')
costs = pd.read_csv('/datasets/costs_us.csv')

for df, name in [(visits, "visits"), (orders, "orders"), (costs, "costs")]:
    print(f"\nDataset: {name}")
    print(f"Shape: {df.shape}")
    print(f"Primeras filas:\n{df.head()}")
    print(f"Columnas:\n{df.columns}")
    print(f"Tipos de datos:\n{df.dtypes}")
    




# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Procura que la importaci√≥n de librer√≠as, carga de datos y exploraci√≥n de estos sea cada paso en celdas separadas para m√°s claridad de lo que est√°s mostrando en cada celda
# </div>

# ## Revisi√≥n de Dataset Visits

# In[23]:


#Revisi√≥n de nombres de columnas del dataset visits
visits.rename(columns={
    'Device': 'device',
    'End Ts': 'end_ts',
    'Source Id': 'source_id',
    'Start Ts': 'start_ts',
    'Uid': 'uid'
}, inplace=True)


#Conversi√≥n de fechas y tiempos
visits['start_ts'] = pd.to_datetime(visits['start_ts'], errors='coerce')
visits['end_ts'] = pd.to_datetime(visits['end_ts'], errors='coerce')


#Revisar si hay errores que no pudieron convertirse (NaT)
print(visits[['start_ts', 'end_ts']].isnull().sum())




# In[24]:


#Calcular la duraci√≥n de la visita
visits['visit_duration_minutes'] = (visits['end_ts'] - visits['start_ts']).dt.total_seconds() / 60
print(visits[visits['visit_duration_minutes'] < 0])


# In[25]:


#Verificar valores categ√≥ricos
print(visits['device'].value_counts())


# In[26]:


#Verifica valores nulos
print(visits.isnull().sum())


# ## Revision de Dataset orders

# In[27]:


#Verificar y corregir nombres de columnas


orders.rename(columns={
    'Buy Ts': 'buy_ts',
    'Revenue': 'revenue',
    'Uid': 'uid',
}, inplace=True)


#Revisar tipos de datos
orders['buy_ts'] = pd.to_datetime(orders['buy_ts'], errors='coerce')
orders['revenue'] = pd.to_numeric(orders['revenue'], errors='coerce')

#Buscar valores faltantes
print(orders.isnull().sum())
print(orders.describe())

#Validar fechas y coherencia temporal
print(orders['buy_ts'].min(), orders['buy_ts'].max())




# # Revision de dataset costs
# 

# In[28]:


##Revisi√≥n de tipo de datos
df['dt'] = pd.to_datetime(df['dt'], errors='coerce')

#Revisi√≥n de Nulos
print(df.isnull().sum())

print(df['costs'].describe())


# In[29]:


#Revisando como quedan finalmente las bases de datos para trabajar el an√°lisis
for df, name in [(visits, "visits"), (orders, "orders"), (costs, "costs")]:
    print(f"\nDataset: {name}")
    print(f"Shape: {df.shape}")
    print(f"Primeras filas:\n{df.head()}")
    print(f"Columnas:\n{df.columns}")
    print(f"Tipos de datos:\n{df.dtypes}")


# In[30]:


print (visits.columns)
print(orders.columns)
print(costs.columns)


# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Buen trabajo con la exploraci√≥n iniial de tus datos! Procura no tener varios procesos que generen m√°s de una salida en una sola celda, por ejemplo, no tengas varios `.info()` en una misma celda sino en varios para que sea clara que parte genera cada salida
# </div>

# # 2. Haz informes y calcula m√©tricas 
# 	Visitas:
# 1.	¬øCu√°ntas personas lo usan cada d√≠a, semana y mes?
# 2.	¬øCu√°ntas sesiones hay por d√≠a? (Un usuario puede tener m√°s de una sesi√≥n).
# 3.	¬øCu√°l es la duraci√≥n de cada sesi√≥n?
# 4.	¬øCon qu√© frecuencia los usuarios regresan?

# ## 1.Visitas

# #### 1.1.¬øCu√°ntas personas lo usan por d√≠a, semana y mes ?

# In[31]:


# Asegurarnos de que start_ts est√© en formato datetime
visits['start_ts'] = pd.to_datetime(visits['start_ts'])

# Extraemos el d√≠a, semana y mes
visits['day'] = visits['start_ts'].dt.date
visits['week'] = visits['start_ts'].dt.isocalendar().week
visits['month'] = visits['start_ts'].dt.month

# N√∫mero de usuarios √∫nicos por d√≠a, semana y mes
usuarios_por_dia = visits.groupby('day')['uid'].nunique()
usuarios_por_semana = visits.groupby('week')['uid'].nunique()
usuarios_por_mes = visits.groupby('month')['uid'].nunique()

# C√°lculo del promedio de usuarios activos
dau_promedio = usuarios_por_dia.mean()  # Promedio diario
wau_promedio = usuarios_por_semana.mean()  # Promedio semanal
mau_promedio = usuarios_por_mes.mean()  # Promedio mensual

# Resultados finales
print(f"Promedio de DAU (Usuarios Activos Diarios): {dau_promedio:.2f}")
print(f"Promedio de WAU (Usuarios Activos Semanales): {wau_promedio:.2f}")
print(f"Promedio de MAU (Usuarios Activos Mensuales): {mau_promedio:.2f}")



# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Est√° bien calcular estas m√©tricas por cada mes, d√≠a o semana pero para presentar las m√©trias de DAU, MAE, WAU debes mostrar un s√≥lo valor, es decir de los resultados que ya tienes saca el promedio para mostrar los usuarios.
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (2da Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Muy bien, si bien es bueno revisar a detalle cada m√©trica al momento de comunicar hay que presentarlo de manera general y s√≥lo si se necesita revisar algo puntual hacerlo m√°s a detalle
# </div>

# #### 1.2. ¬øCu√°ntas sesiones hay por d√≠a? (Un usuario puede tener m√°s de una sesi√≥n).

# In[32]:


# Contar sesiones por d√≠a
sesiones_por_dia = visits.groupby('day')['uid'].count()  # Usamos 'uid' para contar las sesiones

sesiones_por_dia_df = sesiones_por_dia.reset_index()
sesiones_por_dia_df.columns = ['D√≠a', 'Sesiones']  # Renombrar columnas# Calcular el promedio de sesiones por d√≠a
promedio_sesiones = sesiones_por_dia.mean()

#print(sesiones_por_dia_df)
print(f"Promedio de sesiones por d√≠a: {promedio_sesiones:.2f}")


# #### 1.3.¬øCu√°l es la duraci√≥n de cada sesi√≥n?
# 

# In[33]:


# Asegurarnos de que visit_duration_minutes est√© en minutos
visits['visit_duration_minutes'] = (visits['end_ts'] - visits['start_ts']).dt.total_seconds() / 60

# Promedio diario
promedio_diario = visits.groupby(visits['start_ts'].dt.date)['visit_duration_minutes'].mean().mean()

# Promedio semanal
visits['week'] = visits['start_ts'].dt.to_period('W').dt.start_time  # Agregar columna de semana
promedio_semanal = visits.groupby('week')['visit_duration_minutes'].mean().mean()

# Promedio mensual
visits['month'] = visits['start_ts'].dt.to_period('M').dt.start_time  # Agregar columna de mes
promedio_mensual = visits.groupby('month')['visit_duration_minutes'].mean().mean()

# Resultados
print(f"Duraci√≥n promedio de las sesiones (en minutos):")
print(f"Por d√≠a: {promedio_diario:.2f} minutos")
print(f"Por semana: {promedio_semanal:.2f} minutos")
print(f"Por mes: {promedio_mensual:.2f} minutos")


# #### 1.4 ¬øCon que frecuencia los usuarios regresan ?

# In[34]:


# Aseg√∫rate de que las fechas est√©n en el formato correcto
visits['start_ts'] = pd.to_datetime(visits['start_ts'])

# Ordenamos por usuario y fecha de visita
visits.sort_values(by=['uid', 'start_ts'], inplace=True)

# Calculamos la fecha de la visita anterior para cada usuario
visits['previous_visit'] = visits.groupby('uid')['start_ts'].shift(1)

# Calculamos la diferencia en d√≠as entre visitas
visits['time_between_visits'] = (visits['start_ts'] - visits['previous_visit']).dt.days

# Establecemos el per√≠odo de an√°lisis, por ejemplo, 365 d√≠as
periodo_dias = 365

# Filtramos las visitas que ocurrieron dentro del per√≠odo definido
frecuencia_regreso = visits[visits['time_between_visits'] <= periodo_dias]

# Agrupamos por usuario para contar cu√°ntas visitas tiene cada uno dentro del per√≠odo
frecuencia_regreso_por_usuario = frecuencia_regreso.groupby('uid').size()

# Calculamos el promedio de visitas dentro del per√≠odo
promedio_visitas = frecuencia_regreso_por_usuario.mean()

# Imprimimos los resultados
print(f"Promedio de visitas dentro de {periodo_dias} d√≠as: {promedio_visitas:.2f}")


# In[35]:


import matplotlib.pyplot as plt

# Calculamos la frecuencia de visitas dentro de un a√±o (365 d√≠as)
visitas_por_usuario = frecuencia_regreso_por_usuario


bins = range(0, 12, 1)  # Intervalos de 1 en 1, de 0 a 10 visitas

# Graficamos el histograma con los nuevos bins
plt.figure(figsize=(10, 6))  # Tama√±o de la figura
plt.hist(visitas_por_usuario, bins=bins, edgecolor='black', alpha=0.7)
plt.title('Frecuencia de Visitas de los Usuarios en un A√±o (365 d√≠as)', fontsize=14)
plt.xlabel('N√∫mero de Visitas', fontsize=12)
plt.ylabel('N√∫mero de Usuarios', fontsize=12)
plt.grid(True)

# Mostramos el gr√°fico
plt.show()


# Interpretaci√≥n:  Cada usuario regresa 1 o 3 veces al a√±o en promedio. Esto se pudiera considerar bajo, pero si los eventos son de precio elevado quiz√° sea normal  asistir a eventos 1 o 3 veces al a√±o. 

# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Tienes el c√°lculo por cada usuario de manera correcta, pero para presentar los resultados no es correcto presentar los resultados de forma tan granurar por cada usuario. Podr√≠as usar histogramas para ver c√≥mo est√° la distribuci√≥n de las visitas o de cuantas veces regresan los usuarios
# </div>

# ## 2. Ventas

# #### 2.1 ¬øCuando empiezan a comprar los usuarios?
# #### Calcular el tiempo transcurrido entre el registro de un usuario y su primera compra.

# In[36]:


# Combinar las tablas visits y orders
data = visits[['uid', 'start_ts']].drop_duplicates().merge(
    orders[['uid', 'buy_ts']], on='uid', how='inner'
)

# Calcular el tiempo entre registro y la primera compra
data['conversion_days'] = (data['buy_ts'] - data['start_ts']).dt.days

#conversion_days: Representa cu√°ntos d√≠as despu√©s del registro ocurri√≥ la primera compra.

#Categorizar en cohortes de conversi√≥n

def categorize_conversion(days):
    if days == 0:
        return 'Conversion 0d'
    elif days == 1:
        return 'Conversion 1d'
    elif days <= 7:
        return 'Conversion 2-7d'
    elif days <= 30:
        return 'Conversion 8-30d'
    else:
        return 'Conversion >30d'

data['conversion_cohort'] = data['conversion_days'].apply(categorize_conversion)


# Contar usuarios por cohorte
conversion_analysis = data.groupby('conversion_cohort')['uid'].nunique().reset_index()
conversion_analysis.columns = ['Conversion Cohort', 'User Count']

# Ordenar para visualizaci√≥n
conversion_analysis.sort_values(by='User Count', ascending=False, inplace=True)

print("Distribuci√≥n de usuarios por cohorte de conversi√≥n:")
print(conversion_analysis)



# In[37]:


import matplotlib.pyplot as plt

# Crear la gr√°fica de barras
plt.figure(figsize=(10, 6))  # Tama√±o de la figura
plt.bar(conversion_analysis['Conversion Cohort'], conversion_analysis['User Count'], color='skyblue')

# A√±adir t√≠tulo y etiquetas
plt.title('Distribuci√≥n de Usuarios por Cohorte de Conversi√≥n', fontsize=14)
plt.xlabel('Cohorte de Conversi√≥n', fontsize=12)
plt.ylabel('N√∫mero de Usuarios', fontsize=12)

# Mejorar la visualizaci√≥n (rotaci√≥n de etiquetas si es necesario)
plt.xticks(rotation=45)

# Mostrar la gr√°fica
plt.tight_layout()  # Asegura que las etiquetas no se corten
plt.show()


# Este an√°lisis puede ser √∫til para comprender los ciclos de decisi√≥n de los usuarios y tomar decisiones sobre cu√°ndo y c√≥mo optimizar las estrategias de marketing y retenci√≥n para incentivar las conversiones m√°s r√°pidas o mejorar la retenci√≥n de los usuarios que tardan m√°s tiempo en convertir. 0d y 1d son usuarios que se registraron y les tom√≥ de 0 a 1 d√≠as para realizar la compra, son usuarios donde se logra una conversi√≥n r√°pida.

# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Muy bien! Aqu√≠ podr√≠as complementar con una gr√°fica de barras tambi√©n
# </div>

# #### 2.2 ¬øCu√°ntos pedidos hacen durante un periodo de tiempo?

# In[38]:


# Definir el per√≠odo de tiempo
start_date = '2018-01-01'
end_date = '2018-12-31'

# Filtrar pedidos en el rango de tiempo
pedidos_periodo = orders[(orders['buy_ts'] >= start_date) & (orders['buy_ts'] <= end_date)]

# Contar la cantidad de pedidos en el per√≠odo
cantidad_pedidos = pedidos_periodo.shape[0]

print(f"N√∫mero de pedidos entre {start_date} y {end_date}: {cantidad_pedidos}")


# #### 2.3 ¬øCu√°l es el tama√±o promedio de compra?

# In[39]:


# Calcular el tama√±o promedio de compra
tamano_promedio_compra = orders['revenue'].mean()

print(f"El tama√±o promedio de compra es: ${tamano_promedio_compra:.2f}")


# #### 2.4 ¬øCu√°nto dinero traen? (LTV - Lifetime Value)
# #### El LTV (Valor del Tiempo de Vida) mide cu√°nto dinero aporta un cliente durante su tiempo como usuario.

# In[40]:


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Asegurarse de que las columnas 'buy_ts' y 'start_ts' sean de tipo datetime
orders['buy_ts'] = pd.to_datetime(orders['buy_ts'])
visits['start_ts'] = pd.to_datetime(visits['start_ts'])

# Crear la cohorte de conversi√≥n basada en el primer registro de cada usuario
visits['conversion_cohort'] = visits.groupby('uid')['start_ts'].transform('min').dt.to_period('M')

# Crear un periodo relativo de pedidos desde la cohorte de conversi√≥n
orders = orders.merge(
    visits[['uid', 'conversion_cohort']], 
    on='uid', 
    how='left'
)
orders['order_period'] = ((orders['buy_ts'].dt.to_period('M') - orders['conversion_cohort']).apply(lambda x: x.n) + 1)

# Calcular el ingreso total por usuario y periodo relativo
ltv_por_usuario_periodo = orders.groupby(['conversion_cohort', 'order_period'])['revenue'].sum().reset_index()

# Crear una tabla din√°mica para calcular el LTV por cohorte y periodo relativo
pivot_table = ltv_por_usuario_periodo.pivot_table(
    index='conversion_cohort', 
    columns='order_period', 
    values='revenue', 
    aggfunc='sum', 
    fill_value=0  # Rellenar valores nulos con 0
)
#print(pivot_table)

# Convertir el √≠ndice de la tabla pivote a cadenas para evitar errores
pivot_table.index = pivot_table.index.astype(str)

# Crear el mapa de calor
plt.figure(figsize=(12, 8))
sns.heatmap(
    pivot_table,
    cmap="YlGnBu",       # Escala de color
    annot=True,          # Mostrar valores en las celdas
    fmt=".0f",           # Formato sin decimales
    cbar_kws={'label': 'Ingresos ($)'},  # Etiqueta de la barra de color
)

# Configurar el gr√°fico
plt.title("Mapa de calor de LTV por cohorte de conversi√≥n y periodo relativo", fontsize=16)
plt.xlabel("Periodo relativo (meses desde la conversi√≥n)", fontsize=12)
plt.ylabel("Cohorte de conversi√≥n", fontsize=12)
plt.xticks(rotation=45, ha="right")  # Rotar etiquetas en el eje X
plt.tight_layout()

# Mostrar el gr√°fico
plt.show()


# #### Interpretaci√≥n
# La cohorte 2017-06 tiene el mayor LTV acumulado y contribuye de manera significativa en todos los per√≠odos. Esto refleja una estrategia efectiva de adquisici√≥n y retenci√≥n de clientes durante ese per√≠odo.
# El crecimiento sostenido en los per√≠odos posteriores sugiere una base de clientes con mayor fidelidad y h√°bitos de compra recurrentes.
# 
# Rendimiento Decreciente en Cohortes Posteriores:
# A partir de 2017-07, las cohortes presentan una disminuci√≥n en el LTV inicial y una ca√≠da m√°s r√°pida en los per√≠odos posteriores. Esto podr√≠a deberse a:
# Menor efectividad en las campa√±as de adquisici√≥n.
# Clientes con menor poder adquisitivo o menor compromiso a largo plazo.
# 
# Picos Espec√≠ficos y Retenci√≥n Baja:
# La cohorte 2017-09 muestra un pico excepcional en el per√≠odo 4 (782,662.32), seguido de una ca√≠da abrupta. Esto sugiere una promoci√≥n puntual o evento que atrajo clientes, pero sin estrategias suficientes para mantenerlos activos a largo plazo.
# 
# Cohortes de 2018 con LTV Bajo:
# Las cohortes de 2018-01 en adelante presentan un LTV inicial m√°s bajo y ca√≠das r√°pidas en los per√≠odos siguientes.
# 

# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Nuevamente la situaci√≥n de presentar los resultados de manera tan granular por cada usuario, aqu√≠ podr√≠as calcular el LTV por cada cohort apoy√°ndote de pivot_table y el resultado de esto lo graficas en una gr√°fica tipo mapa de calor
# </div>

# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (2da Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Debes calcularlo por cada cohort, es decir, por cada mes c√≥mo lo haces m√°s adelante con la m√©trica de gastos
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (3ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Muy bien, as√≠ tiene m√°s detalle la m√©trica para cada cohort
# </div>

# ## 3. Marketing

# 1¬øCu√°nto dinero se gast√≥? (Total/por fuente de adquisici√≥n/a lo largo del tiempo) 2. ¬øCu√°l fue el costo de adquisici√≥n de clientes de cada una de las fuentes? 3. ¬øCu√°n rentables eran las inversiones? (ROMI)

# #### 3.1 ¬øCu√°nto dinero se gast√≥?

# In[41]:


import seaborn as sns
import matplotlib.pyplot as plt

# Asegurarse de que la columna 'dt' est√© en formato datetime
costs['dt'] = pd.to_datetime(costs['dt'])

# Crear una columna para el mes
costs['month'] = costs['dt'].dt.to_period('M')

# Crear la pivot table para sumar los costos por fuente y mes
pivot_table = costs.pivot_table(
    index='month',       # √çndice ser√° el mes
    columns='source_id', # Columnas ser√°n las fuentes de adquisici√≥n
    values='costs',      # Valores a sumar ser√°n los costos
    aggfunc='sum',       # Agregaci√≥n ser√° la suma
    fill_value=0         # Rellenar valores nulos con 0
)
print(pivot_table)

# Convertir el √≠ndice de la tabla pivote a cadenas para evitar errores
pivot_table.index = pivot_table.index.astype(str)

# Crear el mapa de calor
plt.figure(figsize=(12, 8))
sns.heatmap(
    pivot_table,
    cmap="YlGnBu",       # Escala de color
    annot=True,          # Mostrar valores en las celdas
    fmt=".0f",           # Formato sin decimales
    cbar_kws={'label': 'Gastos ($)'},  # Etiqueta de la barra de color
)

# Configurar el gr√°fico
plt.title("Mapa de calor de gastos por fuente de adquisici√≥n y mes", fontsize=16)
plt.xlabel("Fuente de adquisici√≥n", fontsize=12)
plt.ylabel("Mes", fontsize=12)
plt.xticks(rotation=45, ha="right")  # Rotar etiquetas en el eje X
plt.tight_layout()

# Mostrar el gr√°fico
plt.show()


# 
# Distribuci√≥n de los costos por fuente:
# 
# Las fuentes con los IDs 3 y 4 presentan consistentemente los gastos m√°s altos en todos los meses, lo que sugiere que son fuentes principales de adquisici√≥n.
# Las fuentes con los IDs 9 y 10 tienen gastos significativamente m√°s bajos, indicando que podr√≠an ser canales secundarios o que reciben menor inversi√≥n.

# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Muy bien calculado los gastos por cada cohort y fuente! Complementa esta parte con una gr√°fica tipo mapa de calor
# </div>

# #### 3.2. ¬øCu√°l fue el costo de adquisici√≥n de clientes (CAC) de cada una de las fuentes?

# In[42]:


#El CAC se calcula dividiendo el total gastado por el n√∫mero de clientes adquiridos (uid
# N√∫mero de clientes √∫nicos por fuente
clientes_por_fuente = visits.groupby('source_id')['uid'].nunique().reset_index()
clientes_por_fuente.columns = ['source_id', 'clientes']

# Combinar con los gastos
cac = gastos_por_fuente.merge(clientes_por_fuente, on='source_id')
cac['cac'] = cac['costs'] / cac['clientes']

print(cac)


# In[ ]:


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Asegurarse de que las fechas est√©n en formato datetime
visits['start_ts'] = pd.to_datetime(visits['start_ts'])
visits['month'] = visits['start_ts'].dt.to_period('M')

costs['dt'] = pd.to_datetime(costs['dt'])
costs['month'] = costs['dt'].dt.to_period('M')

# 2. N√∫mero de clientes √∫nicos por fuente y mes
clientes_por_cohort = visits.groupby(['month', 'source_id'])['uid'].nunique().reset_index()
clientes_por_cohort.columns = ['month', 'source_id', 'clientes']

# 3. Gastos totales por fuente y mes
gastos_por_cohort = costs.groupby(['month', 'source_id'])['costs'].sum().reset_index()

# 4. Combinar datos de clientes y gastos
cac_cohort = gastos_por_cohort.merge(clientes_por_cohort, on=['month', 'source_id'], how='left')
cac_cohort['cac'] = cac_cohort['costs'] / cac_cohort['clientes']

# 5. Crear una tabla pivote para el mapa de calor
pivot_cac = cac_cohort.pivot_table(
    index='month', 
    columns='source_id', 
    values='cac', 
    aggfunc='mean', 
    fill_value=0
)

# 6. Generar el mapa de calor
plt.figure(figsize=(12, 8))
sns.heatmap(
    pivot_cac, 
    cmap="YlGnBu", 
    annot=True, 
    fmt=".2f", 
    cbar_kws={'label': 'Costo de Adquisici√≥n (CAC)'}
)
plt.title("Mapa de calor del Costo de Adquisici√≥n por Fuente y Mes", fontsize=16)
plt.xlabel("Fuente de adquisici√≥n")
plt.ylabel("Mes")
plt.show()


# Comparaci√≥n de CAC por Fuente
# El CAC m√°s alto se encuentra en la fuente 3, con 1.89. Esto significa que adquirir un cliente a trav√©s de esta fuente cuesta $1.89 en promedio, lo cual podr√≠a indicar que es una fuente costosa o menos eficiente.
# 
# El CAC m√°s bajo es de la fuente 9, con 0.59. Esto implica que esta fuente es m√°s econ√≥mica para adquirir clientes, con un costo promedio de $0.59 por cliente.
# 
# Relaci√≥n entre "costs" y "clientes"
# 
# Las fuentes 3 y 4 tienen grandes diferencias en eficiencia:
# 
#  Fuente 3: Aunque tiene el gasto m√°s alto (141,321.63), su CAC es el mayor (1.89), lo que sugiere que no genera tantos clientes en relaci√≥n con la inversi√≥n.
#  Fuente 4: A pesar de gastar menos (61,073.60), tiene un CAC mucho m√°s bajo (0.73), lo que indica que es m√°s efectiva en atraer clientes.
#  Evaluaci√≥n de la Eficiencia
#  Fuentes con CAC bajo (como 4, 5, 9, y 10) pueden ser consideradas m√°s eficientes, ya que logran atraer clientes a menor costo.
#  Fuentes con CAC alto (como 3 y 2) deber√≠an ser analizadas para entender si los clientes obtenidos son de mayor calidad o si existen problemas en su estrategia de adquisici√≥n.
# 

# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# El CAC tambi√©n podr√≠as calcularlo por cada cohort y fuente y mostrarlo en una gr√°fica tipo mapa de calor
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (2da Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Perfecto, as√≠ es mucho m√°s claro revisar que cohort tuvo mayor o menor costo de adquisici√≥n
# </div>

# #### 3.3 ¬øCu√°n rentables eran las inversiones? (ROMI)

# El ROMI (Return on Marketing Investment) se calcula como:
# 
# ùëÖùëÇùëÄùêº=
# (Ingresos¬†generados‚àíCostos¬†de¬†marketing)/Costos de Marketing
# 

# # ¬øCu√°n rentables eran las inversiones? (ROMI)

# In[ ]:


# Asegurarnos de que las fechas est√°n en formato datetime
orders['buy_ts'] = pd.to_datetime(orders['buy_ts'])
costs['dt'] = pd.to_datetime(costs['dt'])

# Sumar ingresos (revenue) por cada fuente de adquisici√≥n
revenue_per_source = visits.merge(orders, on='uid', how='inner') \
                           .groupby('source_id')['revenue'].sum()

# Sumar costos de marketing por cada fuente
costs_per_source = costs.groupby('source_id')['costs'].sum()

# Calcular el ROMI por fuente
romi_data = pd.DataFrame({
    'total_revenue': revenue_per_source,
    'total_costs': costs_per_source
})

romi_data['romi'] = (romi_data['total_revenue'] / romi_data['total_costs']) - 1

# Crear la pivot table (tabla din√°mica) con ROMI por fuente
pivot_table_romi = romi_data.reset_index()

# Mostrar la tabla
print(pivot_table_romi)

# Graficar ROMI por fuente de adquisici√≥n
plt.figure(figsize=(10, 6))
plt.bar(pivot_table_romi['source_id'], pivot_table_romi['romi'], color='skyblue')
plt.title('ROMI por Fuente de Adquisici√≥n')
plt.xlabel('Fuente de Adquisici√≥n (source_id)')
plt.ylabel('ROMI')
plt.xticks(pivot_table_romi['source_id'], rotation=45)
plt.tight_layout()
plt.show()


# # Interpretaci√≥n de los resultados: 
#     
# Fuentes altamente rentables: Las fuentes 1, 2, 5, y 4 tienen altos ROMI, siendo las mejores opciones para priorizar inversiones.
# Fuentes de bajo rendimiento: La fuente 3 tiene un ROMI apenas positivo, por lo que se debe evaluar si es necesario optimizar su estrategia.
# Fuentes sin datos completos: La fuente 7 tiene datos incompletos; es necesario verificar si realmente hubo costos asociados.
# Este an√°lisis ayuda a tomar decisiones estrat√©gicas sobre d√≥nde enfocar los recursos de marketing para maximizar la rentabilidad.

# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Ten cuidado con el tipo de celdas que declares, esta deber√≠a ser tipo Markdown para evitar el error de sintaxis
# </div>

# # Escribe una conclusi√≥n: aconseja a los expertos de marketing cu√°nto dinero invertir y d√≥nde

# # Recomendaciones de inversi√≥n:
# 1. Optimizar la inversi√≥n en fuentes de alta rentabilidad (ROMI alto):
# Fuente 1 y Fuente 5:
# Estas fuentes muestran un ROMI alto (109.31 y 21.82 respectivamente). Aumentar la inversi√≥n aqu√≠ podr√≠a maximizar los ingresos, especialmente en el caso de Fuente 1, que tiene el ROMI m√°s alto.
# 
# 2. Reducir o reevaluar fuentes con bajo ROMI:
# Fuente 3 y Fuente 10:
# Estas fuentes tienen ROMIs bajos (1.10 y 1.51 respectivamente), lo que indica que el retorno no compensa los costos. Considera reducir la inversi√≥n o analizar estrategias espec√≠ficas para mejorar su rendimiento.
# 
# 3. Incentivar la retenci√≥n a largo plazo (LTV alto):
# Los usuarios que convierten despu√©s de 30 d√≠as (Conversion >30d) tienen el LTV m√°s alto ($925.74). Implementa estrategias de remarketing y engagement para retener usuarios a largo plazo y aumentar su valor.
# 
# 4. CAC m√°s bajo no siempre significa mejor fuente:
# Aunque Fuente 9 y Fuente 10 tienen el CAC m√°s bajo ($0.60 y $0.72 respectivamente), su ROMI es bajo (5.59 y 1.51). Aseg√∫rate de evaluar el impacto real de estas fuentes en los ingresos.
# 
# 5. Distribuci√≥n de presupuesto por mes:
# Picos de gasto: Octubre, noviembre y diciembre de 2017.
# Estos meses presentan altos costos y deben correlacionarse con los ingresos generados en ese periodo para justificar las inversiones.
# Meses de bajo gasto: Enero a mayo de 2018.
# Analiza si estas inversiones limitadas afectaron la adquisici√≥n o conversi√≥n de usuarios.
# 
# 
# Distribuir m√°s presupuesto a Fuente 1 y Fuente 5, dado su alto ROMI y potencial de generaci√≥n de ingresos.
# Reducir gastos en Fuente 3 y Fuente 10 o implementar estrategias espec√≠ficas para aumentar su rentabilidad.
# Aumentar el enfoque en retenci√≥n y remarketing para usuarios con potencial de conversi√≥n tard√≠a (Conversion >30d), ya que estos usuarios generan el mayor LTV.
# Evaluar estacionalidad: Realiza un an√°lisis estacional para identificar los meses m√°s rentables y ajustar el presupuesto de marketing de acuerdo con las tendencias de comportamiento del usuario.
# 
# 

# <div class="alert alert-block alert-danger">
# <b>Comentario general (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Buen avance de tu proyecto Alejandra! Sin embargo tienes varios puntos de mejora en los que te he dejado comentarios para esto, tambi√©nte pedir√≠a que seas m√°s detallada en la conclusi√≥n final y las recomendaciones ya que aqu√≠ debes hacer tipo un res√∫men de todos los hallazgos desde el inicio del notebook pero enfoc√°ndote en los puntos principales.
#     
# Tambi√©n te pedir√≠a redactar tus interpretaciones de los c√°lculos o visualizaciones que presentes ya que hay varias secciones que solo presentas n√∫meros sin ninguna explicaci√≥n y es importante comunicar de manera clara lo que se est√° presentando.
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (4ta Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Buen t
# </div>
